{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.6 (default, Oct 18 2022, 12:41:40) \n",
      "[Clang 14.0.0 (clang-1400.0.29.202)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chandlerward/car-scraper/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response JSON: {'args': {}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.32.3', 'X-Amzn-Trace-Id': 'Root=1-67cdda8b-50fb53ef6549d08b37c15266'}, 'origin': '172.59.152.206', 'url': 'https://httpbin.org/get'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://httpbin.org/get\"  # A test API that returns request details\n",
    "response = requests.get(url)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)  # Should print 200 if successful\n",
    "print(\"Response JSON:\", response.json())  # Prints the response in JSON format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Found Cars: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Target URL\n",
    "url = \"https://cars.ksl.com/search/body/Convertible\"\n",
    "\n",
    "# Use a user-agent to avoid basic bot detection\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Send request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if request was successful\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Extract car titles\n",
    "car_titles = [title.text.strip() for title in soup.select(\".listing-title\")]\n",
    "\n",
    "# Print results\n",
    "print(\"Found Cars:\", car_titles[:5])  # Print first 5 car titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening KSL Cars...\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "Page.goto: Timeout 30000ms exceeded.\nCall log:\n  - navigating to \"https://cars.ksl.com/search/body/Convertible\", waiting until \"networkidle\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Run the async function\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m cars \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscrape_ksl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[1;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCar Titles\u001b[39m\u001b[38;5;124m\"\u001b[39m: cars})\n",
      "File \u001b[0;32m~/car-scraper/venv/lib/python3.9/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/tasks.py:256\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mscrape_ksl\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Visit the page\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpening KSL Cars...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mgoto(url, wait_until\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetworkidle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Extract car titles\u001b[39;00m\n\u001b[1;32m     23\u001b[0m car_titles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m page\u001b[38;5;241m.\u001b[39mlocator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.listing-title\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mall_inner_texts()\n",
      "File \u001b[0;32m~/car-scraper/venv/lib/python3.9/site-packages/playwright/async_api/_generated.py:8985\u001b[0m, in \u001b[0;36mPage.goto\u001b[0;34m(self, url, timeout, wait_until, referer)\u001b[0m\n\u001b[1;32m   8924\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgoto\u001b[39m(\n\u001b[1;32m   8925\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8926\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8932\u001b[0m     referer: typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   8933\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   8934\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Page.goto\u001b[39;00m\n\u001b[1;32m   8935\u001b[0m \n\u001b[1;32m   8936\u001b[0m \u001b[38;5;124;03m    Returns the main resource response. In case of multiple redirects, the navigation will resolve with the first\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8981\u001b[0m \u001b[38;5;124;03m    Union[Response, None]\u001b[39;00m\n\u001b[1;32m   8982\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   8984\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mfrom_impl_nullable(\n\u001b[0;32m-> 8985\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_obj\u001b[38;5;241m.\u001b[39mgoto(\n\u001b[1;32m   8986\u001b[0m             url\u001b[38;5;241m=\u001b[39murl, timeout\u001b[38;5;241m=\u001b[39mtimeout, waitUntil\u001b[38;5;241m=\u001b[39mwait_until, referer\u001b[38;5;241m=\u001b[39mreferer\n\u001b[1;32m   8987\u001b[0m         )\n\u001b[1;32m   8988\u001b[0m     )\n",
      "File \u001b[0;32m~/car-scraper/venv/lib/python3.9/site-packages/playwright/_impl/_page.py:551\u001b[0m, in \u001b[0;36mPage.goto\u001b[0;34m(self, url, timeout, waitUntil, referer)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgoto\u001b[39m(\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    546\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    549\u001b[0m     referer: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    550\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Response]:\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_main_frame\u001b[38;5;241m.\u001b[39mgoto(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlocals_to_params(\u001b[38;5;28mlocals\u001b[39m()))\n",
      "File \u001b[0;32m~/car-scraper/venv/lib/python3.9/site-packages/playwright/_impl/_frame.py:145\u001b[0m, in \u001b[0;36mFrame.goto\u001b[0;34m(self, url, timeout, waitUntil, referer)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgoto\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    137\u001b[0m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     referer: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    141\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Response]:\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    143\u001b[0m         Optional[Response],\n\u001b[1;32m    144\u001b[0m         from_nullable_channel(\n\u001b[0;32m--> 145\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoto\u001b[39m\u001b[38;5;124m\"\u001b[39m, locals_to_params(\u001b[38;5;28mlocals\u001b[39m()))\n\u001b[1;32m    146\u001b[0m         ),\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m~/car-scraper/venv/lib/python3.9/site-packages/playwright/_impl/_connection.py:61\u001b[0m, in \u001b[0;36mChannel.send\u001b[0;34m(self, method, params)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, params: Dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mwrap_api_call(\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_send(method, params, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_internal_type,\n\u001b[1;32m     64\u001b[0m     )\n",
      "File \u001b[0;32m~/car-scraper/venv/lib/python3.9/site-packages/playwright/_impl/_connection.py:528\u001b[0m, in \u001b[0;36mConnection.wrap_api_call\u001b[0;34m(self, cb, is_internal)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m cb()\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m--> 528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m rewrite_error(error, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_st[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapiName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_zone\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTimeoutError\u001b[0m: Page.goto: Timeout 30000ms exceeded.\nCall log:\n  - navigating to \"https://cars.ksl.com/search/body/Convertible\", waiting until \"networkidle\"\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "\n",
    "# Patch asyncio to work in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Target URL\n",
    "url = \"https://cars.ksl.com/search/body/Convertible\"\n",
    "\n",
    "async def scrape_ksl():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)  # Set True to hide the browser\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "\n",
    "        # Visit the page\n",
    "        print(\"Opening KSL Cars...\")\n",
    "        await page.goto(url, wait_until=\"networkidle\")\n",
    "\n",
    "        # Extract car titles\n",
    "        car_titles = await page.locator(\".listing-title\").all_inner_texts()\n",
    "\n",
    "        await browser.close()\n",
    "        return car_titles\n",
    "\n",
    "# Create and get the event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "# Run the async function\n",
    "cars = loop.run_until_complete(scrape_ksl())\n",
    "\n",
    "# Save results\n",
    "df = pd.DataFrame({\"Car Titles\": cars})\n",
    "df.to_csv(\"ksl_cars.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data saved to ksl_cars.csv!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening KSL Cars...\n",
      "Checking for location popup...\n",
      "Checking for cookie consent popup...\n",
      "Waiting for listings to load...\n",
      "Found 24 listings\n",
      "✅ Data saved to ksl_cars.csv!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from playwright.async_api import async_playwright, TimeoutError\n",
    "from playwright_stealth import stealth_async\n",
    "import pandas as pd\n",
    "\n",
    "# Patch asyncio to work in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Target URL\n",
    "url = \"https://cars.ksl.com/search/body/Convertible\"\n",
    "\n",
    "async def handle_popups(page):\n",
    "    try:\n",
    "                \n",
    "        # Wait for and handle location popup\n",
    "        print(\"Checking for location popup...\")\n",
    "        location_button = page.locator('button:has-text(\"Use this location\")')\n",
    "        if await location_button.count() > 0:\n",
    "            print(\"Accepting location...\")\n",
    "            await location_button.click()\n",
    "            await page.wait_for_timeout(1000)  # Wait for popup to disappear    \n",
    "\n",
    "        # Wait for and handle cookie consent popup\n",
    "        print(\"Checking for cookie consent popup...\")\n",
    "        cookie_button = page.locator('button[aria-label=\"Accept\"]').first\n",
    "        if await cookie_button.count() > 0:\n",
    "            print(\"Accepting cookies...\")\n",
    "            await cookie_button.click()\n",
    "            await page.wait_for_timeout(1000)  # Wait for popup to disappear\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error handling popups: {e}\")\n",
    "\n",
    "async def scrape_ksl():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=False,\n",
    "            args=[\n",
    "                '--disable-blink-features=AutomationControlled',\n",
    "                '--disable-dev-shm-usage',\n",
    "                '--no-sandbox'\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        context = await browser.new_context(\n",
    "            viewport={'width': 1920, 'height': 1080},\n",
    "            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "        )\n",
    "        \n",
    "        page = await context.new_page()\n",
    "        await stealth_async(page)\n",
    "        \n",
    "        try:\n",
    "            print(\"Opening KSL Cars...\")\n",
    "            await page.goto(\n",
    "                url,\n",
    "                wait_until=\"domcontentloaded\",\n",
    "                timeout=60000\n",
    "            )\n",
    "            \n",
    "            # Handle any popups before proceeding\n",
    "            await handle_popups(page)\n",
    "            \n",
    "            print(\"Waiting for listings to load...\")\n",
    "            await page.wait_for_selector(\".listing-title\", timeout=60000)\n",
    "            \n",
    "            # Add a small delay to ensure dynamic content loads\n",
    "            await page.wait_for_timeout(2000)\n",
    "            \n",
    "            # Extract car titles\n",
    "            car_titles = await page.locator(\".listing-title\").all_inner_texts()\n",
    "            print(f\"Found {len(car_titles)} listings\")\n",
    "            \n",
    "            # Optional: Take a screenshot to verify what the page looks like\n",
    "            await page.screenshot(path=\"ksl_cars_page.png\")\n",
    "            \n",
    "            return car_titles\n",
    "            \n",
    "        except TimeoutError as e:\n",
    "            print(f\"Timeout error: {e}\")\n",
    "            print(\"Taking error screenshot...\")\n",
    "            await page.screenshot(path=\"error_screenshot.png\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Taking error screenshot...\")\n",
    "            await page.screenshot(path=\"error_screenshot.png\")\n",
    "            return []\n",
    "        finally:\n",
    "            await browser.close()\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    cars = loop.run_until_complete(scrape_ksl())\n",
    "\n",
    "    if cars:\n",
    "        df = pd.DataFrame({\"Car Titles\": cars})\n",
    "        df.to_csv(\"ksl_cars.csv\", index=False)\n",
    "        print(\"✅ Data saved to ksl_cars.csv!\")\n",
    "    else:\n",
    "        print(\"❌ No car listings were found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Failed to run scraper: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening KSL Cars...\n",
      "Checking for location popup...\n",
      "Checking for cookie consent popup...\n",
      "Waiting for listings to load...\n",
      "Extracting listing details...\n",
      "Error extracting listing details: Locator.inner_text: Timeout 30000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\".listing\").first.locator(\".listing-title a\").first\n",
      "\n",
      "Error extracting listing details: Locator.inner_text: Timeout 30000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\".listing\").nth(1).locator(\".listing-title a\").first\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     loop \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\n\u001b[0;32m--> 114\u001b[0m     cars_data \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscrape_ksl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cars_data:\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;66;03m# Create DataFrame with all the extracted data\u001b[39;00m\n\u001b[1;32m    118\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(cars_data)\n",
      "File \u001b[0;32m~/car-scraper/venv/lib/python3.9/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/car-scraper/venv/lib/python3.9/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/selectors.py:562\u001b[0m, in \u001b[0;36mKqueueSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 562\u001b[0m     kev_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting listing details: Locator.inner_text: Timeout 30000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\".listing\").nth(2).locator(\".listing-title a\").first\n",
      "\n",
      "Error extracting listing details: Locator.inner_text: Timeout 30000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\".listing\").nth(3).locator(\".listing-title a\").first\n",
      "\n",
      "Error extracting listing details: Locator.inner_text: Timeout 30000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\".listing\").nth(4).locator(\".listing-title a\").first\n",
      "\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Call log:\n",
      "  - waiting for locator(\".listing\").nth(5).locator(\".listing-title a\").first\n",
      "\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Error extracting listing details: Locator.inner_text: Target page, context or browser has been closed\n",
      "Found 0 complete listings\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from playwright.async_api import async_playwright, TimeoutError\n",
    "from playwright_stealth import stealth_async\n",
    "import pandas as pd\n",
    "\n",
    "# Patch asyncio to work in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Target URL\n",
    "url = \"https://cars.ksl.com/search/body/Convertible\"\n",
    "\n",
    "async def handle_popups(page):\n",
    "    try:\n",
    "        # Wait for and handle location popup\n",
    "        print(\"Checking for location popup...\")\n",
    "        location_button = page.locator('button:has-text(\"Use this location\")')\n",
    "        if await location_button.count() > 0:\n",
    "            print(\"Accepting location...\")\n",
    "            await location_button.click()\n",
    "            await page.wait_for_timeout(1000)\n",
    "\n",
    "        # Wait for and handle cookie consent popup\n",
    "        print(\"Checking for cookie consent popup...\")\n",
    "        cookie_button = page.locator('button[aria-label=\"Accept\"]').first\n",
    "        if await cookie_button.count() > 0:\n",
    "            print(\"Accepting cookies...\")\n",
    "            await cookie_button.click()\n",
    "            await page.wait_for_timeout(1000)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error handling popups: {e}\")\n",
    "\n",
    "async def scrape_ksl():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=False,\n",
    "            args=[\n",
    "                '--disable-blink-features=AutomationControlled',\n",
    "                '--disable-dev-shm-usage',\n",
    "                '--no-sandbox'\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        context = await browser.new_context(\n",
    "            viewport={'width': 1920, 'height': 1080},\n",
    "            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "        )\n",
    "        \n",
    "        page = await context.new_page()\n",
    "        await stealth_async(page)\n",
    "        \n",
    "        try:\n",
    "            print(\"Opening KSL Cars...\")\n",
    "            await page.goto(\n",
    "                url,\n",
    "                wait_until=\"domcontentloaded\",\n",
    "                timeout=60000\n",
    "            )\n",
    "            \n",
    "            await handle_popups(page)\n",
    "            \n",
    "            print(\"Waiting for listings to load...\")\n",
    "            await page.wait_for_selector(\".listing-title\", timeout=60000)\n",
    "            await page.wait_for_timeout(2000)\n",
    "            \n",
    "            # Extract all listings\n",
    "            listings = await page.locator(\".listing\").all()\n",
    "            cars_data = []\n",
    "            \n",
    "            print(\"Extracting listing details...\")\n",
    "            for listing in listings:\n",
    "                try:\n",
    "                    # Extract title and URL\n",
    "                    title_element = listing.locator(\".listing-title a\").first\n",
    "                    title = await title_element.inner_text()\n",
    "                    href = await title_element.get_attribute(\"href\")\n",
    "                    full_url = f\"https://cars.ksl.com{href}\" if href else \"\"\n",
    "                    \n",
    "                    # Extract price (handle potential missing prices)\n",
    "                    price_element = listing.locator(\".listing-price\")\n",
    "                    price = await price_element.inner_text() if await price_element.count() > 0 else \"N/A\"\n",
    "                    \n",
    "                    # Extract location (handle potential missing locations)\n",
    "                    location_element = listing.locator(\".seller-location\")\n",
    "                    location = await location_element.inner_text() if await location_element.count() > 0 else \"N/A\"\n",
    "                    \n",
    "                    cars_data.append({\n",
    "                        \"title\": title,\n",
    "                        \"price\": price,\n",
    "                        \"location\": location,\n",
    "                        \"url\": full_url\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting listing details: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Found {len(cars_data)} complete listings\")\n",
    "            return cars_data\n",
    "            \n",
    "        except TimeoutError as e:\n",
    "            print(f\"Timeout error: {e}\")\n",
    "            await page.screenshot(path=\"error_screenshot.png\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            await page.screenshot(path=\"error_screenshot.png\")\n",
    "            return []\n",
    "        finally:\n",
    "            await browser.close()\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    cars_data = loop.run_until_complete(scrape_ksl())\n",
    "\n",
    "    if cars_data:\n",
    "        # Create DataFrame with all the extracted data\n",
    "        df = pd.DataFrame(cars_data)\n",
    "        \n",
    "        # Save to CSV with all columns\n",
    "        df.to_csv(\"ksl_cars_detailed.csv\", index=False)\n",
    "        print(\"✅ Data saved to ksl_cars_detailed.csv!\")\n",
    "        \n",
    "        # Display first few entries\n",
    "        print(\"\\nFirst few listings:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"❌ No car listings were found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Failed to run scraper: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening KSL Cars...\n",
      "Checking for location popup...\n",
      "Checking for cookie consent popup...\n",
      "Waiting for listings to load...\n",
      "Extracting listing details...\n",
      "Found 24 listings\n",
      "✅ Data saved to ksl_cars_detailed.csv!\n",
      "\n",
      "First few listings:\n",
      "  title price location url\n",
      "0   N/A   N/A      N/A    \n",
      "1   N/A   N/A      N/A    \n",
      "2   N/A   N/A      N/A    \n",
      "3   N/A   N/A      N/A    \n",
      "4   N/A   N/A      N/A    \n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from playwright.async_api import async_playwright, TimeoutError\n",
    "from playwright_stealth import stealth_async\n",
    "import pandas as pd\n",
    "\n",
    "# Patch asyncio to work in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Target URL\n",
    "url = \"https://cars.ksl.com/search/body/Convertible\"\n",
    "\n",
    "async def handle_popups(page):\n",
    "    try:\n",
    "        # Wait for and handle location popup\n",
    "        print(\"Checking for location popup...\")\n",
    "        location_button = page.locator('button:has-text(\"Use this location\")')\n",
    "        if await location_button.count() > 0:\n",
    "            print(\"Accepting location...\")\n",
    "            await location_button.click()\n",
    "            await page.wait_for_timeout(1000)\n",
    "\n",
    "        # Wait for and handle cookie consent popup\n",
    "        print(\"Checking for cookie consent popup...\")\n",
    "        cookie_button = page.locator('button[aria-label=\"Accept\"]').first\n",
    "        if await cookie_button.count() > 0:\n",
    "            print(\"Accepting cookies...\")\n",
    "            await cookie_button.click()\n",
    "            await page.wait_for_timeout(1000)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error handling popups: {e}\")\n",
    "\n",
    "async def scrape_ksl():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=False,\n",
    "            args=[\n",
    "                '--disable-blink-features=AutomationControlled',\n",
    "                '--disable-dev-shm-usage',\n",
    "                '--no-sandbox'\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        context = await browser.new_context(\n",
    "            viewport={'width': 1920, 'height': 1080},\n",
    "            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "        )\n",
    "        \n",
    "        page = await context.new_page()\n",
    "        await stealth_async(page)\n",
    "        \n",
    "        try:\n",
    "            print(\"Opening KSL Cars...\")\n",
    "            await page.goto(url, wait_until=\"domcontentloaded\", timeout=60000)\n",
    "            await handle_popups(page)\n",
    "            \n",
    "            print(\"Waiting for listings to load...\")\n",
    "            # Wait for any listing to be present (using the selector that worked before)\n",
    "            await page.wait_for_selector(\".listing-title\", state=\"attached\", timeout=60000)\n",
    "            \n",
    "            # Add a longer delay for dynamic content\n",
    "            await page.wait_for_timeout(5000)\n",
    "            \n",
    "            print(\"Extracting listing details...\")\n",
    "            # Use evaluate to extract data directly from the page context\n",
    "            cars_data = await page.evaluate(\"\"\"() => {\n",
    "                const listings = Array.from(document.querySelectorAll('.listing'));\n",
    "                return listings.map(listing => {\n",
    "                    const titleElement = listing.querySelector('.listing-title a');\n",
    "                    const priceElement = listing.querySelector('.listing-price');\n",
    "                    const locationElement = listing.querySelector('.seller-location');\n",
    "                    \n",
    "                    return {\n",
    "                        title: titleElement ? titleElement.innerText.trim() : 'N/A',\n",
    "                        price: priceElement ? priceElement.innerText.trim() : 'N/A',\n",
    "                        location: locationElement ? locationElement.innerText.trim() : 'N/A',\n",
    "                        url: titleElement ? 'https://cars.ksl.com' + titleElement.getAttribute('href') : ''\n",
    "                    };\n",
    "                });\n",
    "            }\"\"\")\n",
    "            \n",
    "            print(f\"Found {len(cars_data)} listings\")\n",
    "            \n",
    "            # Take a screenshot for verification\n",
    "            await page.screenshot(path=\"ksl_cars_page.png\")\n",
    "            return cars_data\n",
    "            \n",
    "        except TimeoutError as e:\n",
    "            print(f\"Timeout error: {e}\")\n",
    "            print(\"Taking error screenshot...\")\n",
    "            await page.screenshot(path=\"error_screenshot.png\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Taking error screenshot...\")\n",
    "            await page.screenshot(path=\"error_screenshot.png\")\n",
    "            return []\n",
    "        finally:\n",
    "            await browser.close()\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    cars_data = loop.run_until_complete(scrape_ksl())\n",
    "\n",
    "    if cars_data:\n",
    "        # Create DataFrame with all the extracted data\n",
    "        df = pd.DataFrame(cars_data)\n",
    "        \n",
    "        # Save to CSV with all columns\n",
    "        df.to_csv(\"ksl_cars_detailed.csv\", index=False)\n",
    "        print(\"✅ Data saved to ksl_cars_detailed.csv!\")\n",
    "        \n",
    "        # Display first few entries\n",
    "        print(\"\\nFirst few listings:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"❌ No car listings were found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Failed to run scraper: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening KSL Cars...\n",
      "Checking for location popup...\n",
      "Checking for cookie consent popup...\n",
      "Waiting for listings to load...\n",
      "Extracting listing details...\n",
      "Found 24 listings\n",
      "✅ Data saved to ksl_cars_detailed.csv!\n",
      "\n",
      "First few listings:\n",
      "                                   title     price           location  \\\n",
      "0       2017 Buick Cascada Sport Touring   $12,997   South Jordan, UT   \n",
      "1              2024 Ford Bronco Badlands   $60,684      Bountiful, UT   \n",
      "2              2024 Ford Bronco Badlands   $63,310      Bountiful, UT   \n",
      "3     2023 Ford Bronco Wildtrak Advanced   $52,659  American Fork, UT   \n",
      "4  2025 Mercedes-Benz SL-Class AMG SL 55  $166,045         Draper, UT   \n",
      "\n",
      "        mileage           msrp           make     model               trim  \\\n",
      "0  99,749 Miles            N/A          Buick   Cascada      Sport Touring   \n",
      "1       2 Miles   MSRP $67,785           Ford    Bronco           Badlands   \n",
      "2       2 Miles   MSRP $70,670           Ford    Bronco           Badlands   \n",
      "3  15,120 Miles            N/A           Ford    Bronco  Wildtrak Advanced   \n",
      "4      10 Miles  MSRP $166,045  Mercedes-Benz  SL-Class          AMG SL 55   \n",
      "\n",
      "   year                vin  sellerType                                   url  \n",
      "0  2017  W04WJ3N51HG074649  Dealership  https://cars.ksl.com/listing/9759810  \n",
      "1  2024  1FMEE9BP8RLA98269  Dealership  https://cars.ksl.com/listing/9480785  \n",
      "2  2024  1FMEE9BPXRLB07280  Dealership  https://cars.ksl.com/listing/9520308  \n",
      "3  2023  1FMEE5DP3PLB02635  Dealership  https://cars.ksl.com/listing/9817515  \n",
      "4  2025  W1KVK8AB0SF023993  Dealership  https://cars.ksl.com/listing/9817499  \n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from playwright.async_api import async_playwright, TimeoutError\n",
    "from playwright_stealth import stealth_async\n",
    "import pandas as pd\n",
    "\n",
    "# Patch asyncio to work in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Target URL\n",
    "url = \"https://cars.ksl.com/search/body/Convertible\"\n",
    "\n",
    "async def handle_popups(page):\n",
    "    try:\n",
    "        # Wait for and handle location popup\n",
    "        print(\"Checking for location popup...\")\n",
    "        location_button = page.locator('button:has-text(\"Use this location\")')\n",
    "        if await location_button.count() > 0:\n",
    "            print(\"Accepting location...\")\n",
    "            await location_button.click()\n",
    "            await page.wait_for_timeout(1000)\n",
    "\n",
    "        # Wait for and handle cookie consent popup\n",
    "        print(\"Checking for cookie consent popup...\")\n",
    "        cookie_button = page.locator('button[aria-label=\"Accept\"]').first\n",
    "        if await cookie_button.count() > 0:\n",
    "            print(\"Accepting cookies...\")\n",
    "            await cookie_button.click()\n",
    "            await page.wait_for_timeout(1000)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error handling popups: {e}\")\n",
    "\n",
    "async def scrape_ksl():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=False,\n",
    "            args=[\n",
    "                '--disable-blink-features=AutomationControlled',\n",
    "                '--disable-dev-shm-usage',\n",
    "                '--no-sandbox'\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        context = await browser.new_context(\n",
    "            viewport={'width': 1920, 'height': 1080},\n",
    "            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'\n",
    "        )\n",
    "        \n",
    "        page = await context.new_page()\n",
    "        await stealth_async(page)\n",
    "        \n",
    "        try:\n",
    "            print(\"Opening KSL Cars...\")\n",
    "            await page.goto(url, wait_until=\"domcontentloaded\", timeout=60000)\n",
    "            await handle_popups(page)\n",
    "            \n",
    "            print(\"Waiting for listings to load...\")\n",
    "            # Wait for any listing to be present\n",
    "            await page.wait_for_selector('[data-testid=\"test-responsive\"]', state=\"attached\", timeout=60000)\n",
    "            \n",
    "            # Add a longer delay for dynamic content\n",
    "            await page.wait_for_timeout(5000)\n",
    "            \n",
    "            print(\"Extracting listing details...\")\n",
    "            # Use evaluate to extract data directly from the page context\n",
    "            cars_data = await page.evaluate(\"\"\"() => {\n",
    "                const listings = Array.from(document.querySelectorAll('[data-testid=\"test-responsive\"]'));\n",
    "                return listings.map(listing => {\n",
    "                    // Get the raw listing data from the data-listing attribute\n",
    "                    const listingData = JSON.parse(listing.getAttribute('data-listing') || '{}');\n",
    "                    \n",
    "                    // Get elements using more specific selectors\n",
    "                    const titleElement = listing.querySelector('.listing-title');\n",
    "                    const priceElement = listing.querySelector('.Listing__Prices-sc-1v5k5vh-10 p');\n",
    "                    const locationLink = listing.querySelector('.Listing__LocationLink-sc-1v5k5vh-9');\n",
    "                    const msrpElement = listing.querySelector('p[style*=\"font-size: 0.8em\"]');\n",
    "                    const mileageElement = listing.querySelector('p[style*=\"margin-top: -2px\"]');\n",
    "                    \n",
    "                    return {\n",
    "                        title: titleElement ? titleElement.innerText.trim() : 'N/A',\n",
    "                        price: priceElement ? priceElement.innerText.trim() : 'N/A',\n",
    "                        location: locationLink ? locationLink.innerText.trim() : 'N/A',\n",
    "                        mileage: mileageElement ? mileageElement.innerText.trim() : 'N/A',\n",
    "                        msrp: msrpElement ? msrpElement.innerText.trim() : 'N/A',\n",
    "                        // Data from the listing attribute\n",
    "                        make: listingData.make || 'N/A',\n",
    "                        model: listingData.model || 'N/A',\n",
    "                        trim: listingData.trim || 'N/A',\n",
    "                        year: listingData.makeYear || 'N/A',\n",
    "                        vin: listingData.vin || 'N/A',\n",
    "                        sellerType: listingData.sellerType || 'N/A',\n",
    "                        url: listingData.id ? `https://cars.ksl.com/listing/${listingData.id}` : ''\n",
    "                    };\n",
    "                }).filter(item => item.title !== 'N/A');  // Filter out empty listings\n",
    "            }\"\"\")\n",
    "            \n",
    "            print(f\"Found {len(cars_data)} listings\")\n",
    "            \n",
    "            # Take a screenshot for verification\n",
    "            await page.screenshot(path=\"ksl_cars_page.png\")\n",
    "            return cars_data\n",
    "            \n",
    "        except TimeoutError as e:\n",
    "            print(f\"Timeout error: {e}\")\n",
    "            print(\"Taking error screenshot...\")\n",
    "            await page.screenshot(path=\"error_screenshot.png\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Taking error screenshot...\")\n",
    "            await page.screenshot(path=\"error_screenshot.png\")\n",
    "            return []\n",
    "        finally:\n",
    "            await browser.close()\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    cars_data = loop.run_until_complete(scrape_ksl())\n",
    "\n",
    "    if cars_data:\n",
    "        # Create DataFrame with all the extracted data\n",
    "        df = pd.DataFrame(cars_data)\n",
    "        \n",
    "        # Save to CSV with all columns\n",
    "        df.to_csv(\"ksl_cars_detailed.csv\", index=False)\n",
    "        print(\"✅ Data saved to ksl_cars_detailed.csv!\")\n",
    "        \n",
    "        # Display first few entries\n",
    "        print(\"\\nFirst few listings:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"❌ No car listings were found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Failed to run scraper: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
